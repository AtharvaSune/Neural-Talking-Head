{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" In this file, PyTorch modules are defined to be used in the Talking Heads model. \"\"\"\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "\n",
    "def init_conv(conv):\n",
    "    nn.init.xavier_uniform_(conv.weight)\n",
    "    if conv.bias is not None:\n",
    "        conv.bias.data.zero_()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOG_DIR = r'logs'\n",
    "MODELS_DIR = r'models'\n",
    "GENERATED_DIR = r'generated_img'\n",
    "\n",
    "# Dataset parameters\n",
    "FEATURES_DPI = 100\n",
    "K = 8\n",
    "\n",
    "# Training hyperparameters\n",
    "IMAGE_SIZE = 256  # 224\n",
    "BATCH_SIZE = 3\n",
    "EPOCHS = 1000\n",
    "LEARNING_RATE_E_G = 5e-5\n",
    "LEARNING_RATE_D = 2e-4\n",
    "LOSS_VGG_FACE_WEIGHT = 2e-3\n",
    "LOSS_VGG19_WEIGHT = 1e-2\n",
    "LOSS_MCH_WEIGHT = 8e1\n",
    "LOSS_FM_WEIGHT = 1e1\n",
    "FEED_FORWARD = False\n",
    "SUBSET_SIZE = 140000\n",
    "\n",
    "# Model Parameters\n",
    "E_VECTOR_LENGTH = 512\n",
    "HIDDEN_LAYERS_P = 4096"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self, in_dim):\n",
    "        super(SelfAttention, self).__init__()\n",
    "\n",
    "        self.query_conv = nn.Conv2d(in_channels=in_dim, out_channels=in_dim // 8, kernel_size=1)\n",
    "        self.key_conv = nn.Conv2d(in_channels=in_dim, out_channels=in_dim // 8, kernel_size=1)\n",
    "        self.value_conv = nn.Conv2d(in_channels=in_dim, out_channels=in_dim, kernel_size=1)\n",
    "        self.gamma = nn.Parameter(torch.rand(1).normal_(0.0, 0.02))\n",
    "\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # B: mini batches, C: channels, W: width, H: height\n",
    "        B, C, H, W = x.shape\n",
    "        proj_query = self.query_conv(x).view(B, -1, W * H).permute(0, 2, 1)  # B X CX(N)\n",
    "        proj_key = self.key_conv(x).view(B, -1, W * H)  # B X C x (*W*H)\n",
    "        energy = torch.bmm(proj_query, proj_key)  # transpose check\n",
    "        attention = self.softmax(energy)  # BX (N) X (N)\n",
    "        proj_value = self.value_conv(x).view(B, -1, W * H)  # B X C X N\n",
    "\n",
    "        out = torch.bmm(proj_value, attention.permute(0, 2, 1))\n",
    "        out = out.view(B, C, H, W)\n",
    "\n",
    "        out = self.gamma * out + x\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class ConvLayer(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride, padding=None):\n",
    "        super(ConvLayer, self).__init__()\n",
    "        if padding is None:\n",
    "            padding = kernel_size // 2\n",
    "        self.reflection_pad = nn.ZeroPad2d(padding)\n",
    "        self.conv2d = nn.utils.spectral_norm(nn.Conv2d(in_channels, out_channels, kernel_size, stride))\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.reflection_pad(x)\n",
    "        out = self.conv2d(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class AdaIn(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AdaIn, self).__init__()\n",
    "        self.eps = 1e-5\n",
    "\n",
    "    def forward(self, x, mean_style, std_style):\n",
    "        B, C, H, W = x.shape\n",
    "\n",
    "        feature = x.view(B, C, -1)\n",
    "\n",
    "        std_feat = (torch.std(feature, dim=2) + self.eps).view(B, C, 1)\n",
    "        mean_feat = torch.mean(feature, dim=2).view(B, C, 1)\n",
    "\n",
    "        adain = std_style * (feature - mean_feat) / std_feat + mean_style\n",
    "\n",
    "        adain = adain.view(B, C, H, W)\n",
    "        return adain\n",
    "\n",
    "\n",
    "# endregion\n",
    "\n",
    "# region Non-Adaptive Residual Blocks\n",
    "\n",
    "class ResidualBlockDown(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, padding=None):\n",
    "        super(ResidualBlockDown, self).__init__()\n",
    "\n",
    "        # Right Side\n",
    "        self.conv_r1 = ConvLayer(in_channels, out_channels, kernel_size, stride, padding)\n",
    "        self.conv_r2 = ConvLayer(out_channels, out_channels, kernel_size, stride, padding)\n",
    "\n",
    "        # Left Side\n",
    "        self.conv_l = ConvLayer(in_channels, out_channels, 1, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        # Right Side\n",
    "        out = F.relu(x)\n",
    "        out = self.conv_r1(out)\n",
    "        out = F.relu(out)\n",
    "        out = self.conv_r2(out)\n",
    "        out = F.avg_pool2d(out, 2)\n",
    "\n",
    "        # Left Side\n",
    "        residual = self.conv_l(residual)\n",
    "        residual = F.avg_pool2d(residual, 2)\n",
    "        \n",
    "        # Merge\n",
    "        out = residual + out\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResidualBlockUp(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, upsample=2):\n",
    "        super(ResidualBlockUp, self).__init__()\n",
    "\n",
    "        # General\n",
    "        self.upsample = nn.Upsample(scale_factor=upsample, mode='nearest')\n",
    "\n",
    "        # Right Side\n",
    "        self.norm_r1 = nn.InstanceNorm2d(in_channels, affine=True)\n",
    "        self.conv_r1 = ConvLayer(in_channels, out_channels, kernel_size, stride)\n",
    "\n",
    "        self.norm_r2 = nn.InstanceNorm2d(out_channels, affine=True)\n",
    "        self.conv_r2 = ConvLayer(out_channels, out_channels, kernel_size, stride)\n",
    "\n",
    "        # Left Side\n",
    "        self.conv_l = ConvLayer(in_channels, out_channels, 1, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        # Right Side\n",
    "        out = self.norm_r1(x)\n",
    "        out = F.relu(out)\n",
    "        out = self.upsample(out)\n",
    "        out = self.conv_r1(out)\n",
    "        out = self.norm_r2(out)\n",
    "        out = F.relu(out)\n",
    "        out = self.conv_r2(out)\n",
    "\n",
    "        # Left Side\n",
    "        residual = self.upsample(residual)\n",
    "        residual = self.conv_l(residual)\n",
    "\n",
    "        # Merge\n",
    "        out = residual + out\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, channels):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.conv1 = ConvLayer(channels, channels, kernel_size=3, stride=1)\n",
    "        self.in1 = nn.InstanceNorm2d(channels, affine=True)\n",
    "        self.conv2 = ConvLayer(channels, channels, kernel_size=3, stride=1)\n",
    "        self.in2 = nn.InstanceNorm2d(channels, affine=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.in1(out)\n",
    "        out = F.relu(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.in2(out)\n",
    "\n",
    "        out = out + residual\n",
    "        return out\n",
    "\n",
    "\n",
    "# endregion\n",
    "\n",
    "# region Adaptive Residual Blocks\n",
    "\n",
    "\n",
    "class AdaptiveResidualBlockUp(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, upsample=2):\n",
    "        super(AdaptiveResidualBlockUp, self).__init__()\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "\n",
    "        # General\n",
    "        self.upsample = nn.Upsample(scale_factor=upsample, mode='nearest')\n",
    "\n",
    "        # Right Side\n",
    "        self.norm_r1 = AdaIn()\n",
    "        self.conv_r1 = ConvLayer(in_channels, out_channels, kernel_size, stride)\n",
    "\n",
    "        self.norm_r2 = AdaIn()\n",
    "        self.conv_r2 = ConvLayer(out_channels, out_channels, kernel_size, stride)\n",
    "\n",
    "        # Left Side\n",
    "        self.conv_l = ConvLayer(in_channels, out_channels, 1, 1)\n",
    "\n",
    "    def forward(self, x, mean1, std1, mean2, std2):\n",
    "        residual = x\n",
    "\n",
    "        # Right Side\n",
    "        out = self.norm_r1(x, mean1, std1)\n",
    "        out = F.relu(out)\n",
    "        out = self.upsample(out)\n",
    "        out = self.conv_r1(out)\n",
    "        out = self.norm_r2(out, mean2, std2)\n",
    "        out = F.relu(out)\n",
    "        out = self.conv_r2(out)\n",
    "\n",
    "        # Left Side\n",
    "        residual = self.upsample(residual)\n",
    "        residual = self.conv_l(residual)\n",
    "\n",
    "        # Merge\n",
    "        out = residual + out\n",
    "        return out\n",
    "\n",
    "\n",
    "class AdaptiveResidualBlock(nn.Module):\n",
    "    def __init__(self, channels):\n",
    "        super(AdaptiveResidualBlock, self).__init__()\n",
    "        self.conv1 = ConvLayer(channels, channels, kernel_size=3, stride=1)\n",
    "        self.in1 = AdaIn()\n",
    "        self.conv2 = ConvLayer(channels, channels, kernel_size=3, stride=1)\n",
    "        self.in2 = AdaIn()\n",
    "\n",
    "    def forward(self, x, mean1, std1, mean2, std2):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.in1(out, mean1, std1)\n",
    "        out = F.relu(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.in2(out, mean1, std1)\n",
    "\n",
    "        out = out + residual\n",
    "        return out\n",
    "\n",
    "# endregion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv2d') != -1:\n",
    "        m.weight.data.normal_(0.0, 0.02)\n",
    "    if classname.find('Linear') != -1:\n",
    "        # m.weight.data.normal_(0.0, 0.02)\n",
    "        nn.init.xavier_uniform_(m.weight.data)\n",
    "        m.bias.data.fill_(0)\n",
    "    elif classname.find('InstanceNorm2d') != -1:\n",
    "        m.weight.data.normal_(1.0, 0.02)\n",
    "        m.bias.data.fill_(0)\n",
    "\n",
    "from collections import OrderedDict\n",
    "\n",
    "class Embedder(nn.Module):\n",
    "    \"\"\"\n",
    "    The Embedder network attempts to generate a vector that encodes the personal characteristics of an individual given\n",
    "    a head-shot and the matching landmarks.\n",
    "    \"\"\"\n",
    "    def __init__(self, gpu=None):\n",
    "        super(Embedder, self).__init__()\n",
    "        \n",
    "        \n",
    "        self.conv11 = ResidualBlockDown(2, 2)\n",
    "        self.conv12 = ResidualBlockDown(2, 2)\n",
    "        self.conv1 = ResidualBlockDown(2, 64)\n",
    "        self.conv2 = ResidualBlockDown(64, 128)\n",
    "        self.conv3 = ResidualBlockDown(128, 256)\n",
    "        self.att = SelfAttention(256)\n",
    "        self.conv4 = ResidualBlockDown(256, 512)\n",
    "        self.conv5 = ResidualBlockDown(512, 512)\n",
    "        self.conv6 = ResidualBlockDown(512, 512)\n",
    "\n",
    "        self.pooling = nn.AdaptiveMaxPool2d((1, 1))\n",
    "\n",
    "#         self.apply(weights_init)\n",
    "        self.gpu = gpu\n",
    "        if gpu is not None:\n",
    "            self.cuda(gpu)\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        print(\"Network\", x.shape)\n",
    "        # assert x.dim() == 3 and x.shape[1] == 1, \"Both x and y must be tensors with shape [BxK, 1, W, H].\"\n",
    "        assert x.shape == y.shape, \"Both x and y must be tensors with shape [BxK, 1, W, H].\"\n",
    "        if self.gpu is not None:\n",
    "            x = x.cuda(self.gpu)\n",
    "            y = y.cuda(self.gpu)\n",
    "\n",
    "        # Concatenate x & y\n",
    "        out = torch.cat((x, y), dim=1)  # [BxK, 2, 256, 256]\n",
    "        # Encode\n",
    "        out = self.conv12(self.conv11(out))\n",
    "        \n",
    "        out = (self.conv1(out))  # [BxK, 64, 128, 128]\n",
    "        out = (self.conv2(out))  # [BxK, 128, 64, 64]\n",
    "        out = (self.conv3(out))  # [BxK, 256, 32, 32]\n",
    "        out = self.att(out)\n",
    "        out = (self.conv4(out))  # [BxK, 512, 16, 16]\n",
    "        out = (self.conv5(out))  # [BxK, 512, 8, 8]\n",
    "        out = (self.conv6(out))  # [BxK, 512, 4, 4]\n",
    "\n",
    "        # Vectorize\n",
    "        out = F.relu(self.pooling(out).view(-1, E_VECTOR_LENGTH))\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    ADAIN_LAYERS = OrderedDict([\n",
    "        ('res1', (512, 512)),\n",
    "        ('res2', (512, 512)),\n",
    "        ('res3', (512, 512)),\n",
    "        ('res4', (512, 512)),\n",
    "        ('res5', (512, 512)),\n",
    "        ('deconv6', (512, 512)),\n",
    "        ('deconv5', (512, 512)),\n",
    "        ('deconv4', (512, 256)),\n",
    "        ('deconv3', (256, 128)),\n",
    "        ('deconv2', (128, 64)),\n",
    "        ('deconv1', (64, 3))\n",
    "    ])\n",
    "\n",
    "    def __init__(self, gpu=None):\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        # projection layer\n",
    "        self.PSI_PORTIONS, self.psi_length = self.define_psi_slices()\n",
    "        self.projection = nn.Parameter(torch.rand(self.psi_length, E_VECTOR_LENGTH).normal_(0.0, 0.02))\n",
    "\n",
    "        # encoding layers\n",
    "        self.conv11 = ResidualBlockDown(1, 1)\n",
    "        self.in11_e = nn.InstanceNorm2d(1, affine=True)\n",
    "        \n",
    "        self.conv12 = ResidualBlockDown(1, 1)\n",
    "        self.in12_e = nn.InstanceNorm2d(1, affine=True)\n",
    "        \n",
    "        self.conv1 = ResidualBlockDown(1, 64)\n",
    "        self.in1_e = nn.InstanceNorm2d(64, affine=True)\n",
    "\n",
    "        self.conv2 = ResidualBlockDown(64, 128)\n",
    "        self.in2_e = nn.InstanceNorm2d(128, affine=True)\n",
    "\n",
    "        self.conv3 = ResidualBlockDown(128, 256)\n",
    "        self.in3_e = nn.InstanceNorm2d(256, affine=True)\n",
    "\n",
    "        self.att1 = SelfAttention(256)\n",
    "\n",
    "        self.conv4 = ResidualBlockDown(256, 512)\n",
    "        self.in4_e = nn.InstanceNorm2d(512, affine=True)\n",
    "\n",
    "        self.conv5 = ResidualBlockDown(512, 512)\n",
    "        self.in5_e = nn.InstanceNorm2d(512, affine=True)\n",
    "\n",
    "        self.conv6 = ResidualBlockDown(512, 512)\n",
    "        self.in6_e = nn.InstanceNorm2d(512, affine=True)\n",
    "\n",
    "        # residual layers\n",
    "        self.res1 = AdaptiveResidualBlock(512)\n",
    "        self.res2 = AdaptiveResidualBlock(512)\n",
    "        self.res3 = AdaptiveResidualBlock(512)\n",
    "        self.res4 = AdaptiveResidualBlock(512)\n",
    "        self.res5 = AdaptiveResidualBlock(512)\n",
    "\n",
    "        # decoding layers\n",
    "        self.deconv6 = AdaptiveResidualBlockUp(512, 512, upsample=2)\n",
    "        self.in6_d = nn.InstanceNorm2d(512, affine=True)\n",
    "\n",
    "        self.deconv5 = AdaptiveResidualBlockUp(512, 512, upsample=2)\n",
    "        self.in5_d = nn.InstanceNorm2d(512, affine=True)\n",
    "\n",
    "        self.deconv4 = AdaptiveResidualBlockUp(512, 256, upsample=2)\n",
    "        self.in4_d = nn.InstanceNorm2d(256, affine=True)\n",
    "\n",
    "        self.deconv3 = AdaptiveResidualBlockUp(256, 128, upsample=2)\n",
    "        self.in3_d = nn.InstanceNorm2d(128, affine=True)\n",
    "\n",
    "        self.att2 = SelfAttention(128)\n",
    "\n",
    "        self.deconv2 = AdaptiveResidualBlockUp(128, 64, upsample=2)\n",
    "        self.in2_d = nn.InstanceNorm2d(64, affine=True)\n",
    "\n",
    "        self.deconv1 = AdaptiveResidualBlockUp(64, 1, upsample=2)\n",
    "        self.in1_d = nn.InstanceNorm2d(1, affine=True)\n",
    "        \n",
    "        self.deconv12 = ResidualBlockUp(1, 1, upsample=2)\n",
    "        self.in12_d = nn.InstanceNorm2d(1, affine=True)\n",
    "        \n",
    "        self.deconv11 = ResidualBlockUp(1, 1, upsample=2)\n",
    "        self.in11_d = nn.InstanceNorm2d(1, affine=True)\n",
    "\n",
    "        self.apply(weights_init)\n",
    "        self.gpu = gpu\n",
    "        if gpu is not None:\n",
    "            self.cuda(gpu)\n",
    "\n",
    "    def forward(self, y, e):\n",
    "        if self.gpu is not None:\n",
    "            e = e.cuda(self.gpu)\n",
    "            y = y.cuda(self.gpu)\n",
    "\n",
    "        out = y  # [B, 1, 256, 256]\n",
    "\n",
    "        # Calculate psi_hat parameters\n",
    "        P = self.projection.unsqueeze(0)\n",
    "        P = P.expand(e.shape[0], P.shape[1], P.shape[2])\n",
    "        psi_hat = torch.bmm(P, e.unsqueeze(2)).squeeze(2)\n",
    "\n",
    "        # Encode\n",
    "        out = self.in11_e(self.conv11(out))\n",
    "        out = self.in12_e(self.conv12(out))\n",
    "        out = self.in1_e(self.conv1(out))  # [B, 64, 128, 128]\n",
    "        out = self.in2_e(self.conv2(out))  # [B, 128, 64, 64]\n",
    "        out = self.in3_e(self.conv3(out))  # [B, 256, 32, 32]\n",
    "        out = self.att1(out)\n",
    "        out = self.in4_e(self.conv4(out))  # [B, 512, 16, 16]\n",
    "        out = self.in5_e(self.conv5(out))  # [B, 512, 8, 8]\n",
    "        out = self.in6_e(self.conv6(out))  # [B, 512, 4, 4]\n",
    "\n",
    "        # Residual layers\n",
    "        out = self.res1(out, *self.slice_psi(psi_hat, 'res1'))\n",
    "        out = self.res2(out, *self.slice_psi(psi_hat, 'res2'))\n",
    "        out = self.res3(out, *self.slice_psi(psi_hat, 'res3'))\n",
    "        out = self.res4(out, *self.slice_psi(psi_hat, 'res4'))\n",
    "        out = self.res5(out, *self.slice_psi(psi_hat, 'res5'))\n",
    "\n",
    "        # Decode\n",
    "        out = self.in6_d(self.deconv6(out, *self.slice_psi(psi_hat, 'deconv6')))  # [B, 512, 4, 4]\n",
    "        out = self.in5_d(self.deconv5(out, *self.slice_psi(psi_hat, 'deconv5')))  # [B, 512, 16, 16]\n",
    "        out = self.in4_d(self.deconv4(out, *self.slice_psi(psi_hat, 'deconv4')))  # [B, 256, 32, 32]\n",
    "        out = self.in3_d(self.deconv3(out, *self.slice_psi(psi_hat, 'deconv3')))  # [B, 128, 64, 64]\n",
    "        out = self.att2(out)\n",
    "        out = self.in2_d(self.deconv2(out, *self.slice_psi(psi_hat, 'deconv2')))  # [B, 64, 128, 128]\n",
    "        out = self.in1_d(self.deconv1(out, *self.slice_psi(psi_hat, 'deconv1')))  # [B, 3, 256, 256]\n",
    "        out = self.in12_d(self.deconv12(out))\n",
    "        out = self.in11_d(self.deconv11(out))\n",
    "\n",
    "        out = torch.sigmoid(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "    def slice_psi(self, psi, portion):\n",
    "        idx0, idx1 = self.PSI_PORTIONS[portion]\n",
    "        len1, len2 = self.ADAIN_LAYERS[portion]\n",
    "        aux = psi[:, idx0:idx1].unsqueeze(-1)\n",
    "        mean1, std1 = aux[:, 0:len1], aux[:, len1:2 * len1]\n",
    "        mean2, std2 = aux[:, 2 * len1:2 * len1 + len2], aux[:, 2 * len1 + len2:]\n",
    "        return mean1, std1, mean2, std2\n",
    "\n",
    "    def define_psi_slices(self):\n",
    "        out = {}\n",
    "        d = self.ADAIN_LAYERS\n",
    "        start_idx, end_idx = 0, 0\n",
    "        for layer in d:\n",
    "            end_idx = start_idx + d[layer][0] * 2 + d[layer][1] * 2\n",
    "            out[layer] = (start_idx, end_idx)\n",
    "            start_idx = end_idx\n",
    "\n",
    "        return out, end_idx\n",
    "\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, training_videos, gpu=None):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        self.conv1 = ResidualBlockDown(2, 64)\n",
    "        self.conv2 = ResidualBlockDown(64, 128)\n",
    "        self.conv3 = ResidualBlockDown(128, 256)\n",
    "        self.att = SelfAttention(256)\n",
    "        self.conv4 = ResidualBlockDown(256, 512)\n",
    "        self.conv5 = ResidualBlockDown(512, 512)\n",
    "        self.conv6 = ResidualBlockDown(512, 512)\n",
    "        self.res_block = ResidualBlock(512)\n",
    "\n",
    "        self.pooling = nn.AdaptiveMaxPool2d((1, 1))\n",
    "\n",
    "        self.W = nn.Parameter(torch.rand(512, training_videos).normal_(0.0, 0.02))\n",
    "        self.w_0 = nn.Parameter(torch.rand(512, 1).normal_(0.0, 0.02))\n",
    "        self.b = nn.Parameter(torch.rand(1).normal_(0.0, 0.02))\n",
    "\n",
    "        self.apply(weights_init)\n",
    "        self.gpu = gpu\n",
    "        if gpu is not None:\n",
    "            self.cuda(gpu)\n",
    "\n",
    "    def forward(self, x, y, i):\n",
    "        assert x.dim() == 4 and x.shape[1] == 1, \"Both x and y must be tensors with shape [BxK, 3, W, H].\"\n",
    "        assert x.shape == y.shape, \"Both x and y must be tensors with shape [BxK, 3, W, H].\"\n",
    "\n",
    "        if self.gpu is not None:\n",
    "            x = x.cuda(self.gpu)\n",
    "            y = y.cuda(self.gpu)\n",
    "\n",
    "        # Concatenate x & y\n",
    "        out = torch.cat((x, y), dim=1)  # [B, 6, 256, 256]\n",
    "\n",
    "        # Encode\n",
    "        out_0 = (self.conv1(out))  # [B, 64, 128, 128]\n",
    "        out_1 = (self.conv2(out_0))  # [B, 128, 64, 64]\n",
    "        out_2 = (self.conv3(out_1))  # [B, 256, 32, 32]\n",
    "        out_3 = self.att(out_2)\n",
    "        out_4 = (self.conv4(out_3))  # [B, 512, 16, 16]\n",
    "        out_5 = (self.conv5(out_4))  # [B, 512, 8, 8]\n",
    "        out_6 = (self.conv6(out_5))  # [B, 512, 4, 4]\n",
    "        out_7 = (self.res_block(out_6))\n",
    "\n",
    "        # Vectorize\n",
    "        out = F.relu(self.pooling(out_7)).view(-1, 512, 1)  # [B, 512, 1]\n",
    "\n",
    "        # Calculate Realism Score\n",
    "        _out = out.transpose(1, 2)\n",
    "        _W_i = (self.W[:, i].unsqueeze(-1)).transpose(0, 1)\n",
    "        out = torch.bmm(_out, _W_i + self.w_0) + self.b\n",
    "        out = torch.sigmoid(out)\n",
    "\n",
    "        out = out.reshape(x.shape[0])\n",
    "\n",
    "        return out, [out_0, out_1, out_2, out_3, out_4, out_5, out_6, out_7]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data torch.Size([1, 10, 2, 1, 1024, 1024]), T torch.Size([1, 2, 1, 1024, 1024]) \n",
      "EIN  torch.Size([10, 2, 1, 1024, 1024])\n",
      "Network torch.Size([10, 1, 1024, 1024])\n"
     ]
    }
   ],
   "source": [
    "sample_data = torch.from_numpy(np.random.randint(0, 256, size=(1, 11, 2, 1, 1024, 1024)).astype(np.long))\n",
    "t = sample_data[:, -1, ...]\n",
    "data = sample_data[:, :-1, ...]\n",
    "dims = data.shape\n",
    "print(\"Data {}, T {} \".format(data.shape, t.shape))\n",
    "# Calculate average encoding vector for data\n",
    "e_in = data.reshape(dims[0] * dims[1], dims[2], dims[3], dims[4], dims[5])  # [BxK,2,  C, W, H]\n",
    "print(\"EIN \", e_in.shape)\n",
    "x, y = e_in[:, 0, ...], e_in[:, 1, ...]\n",
    "E = Embedder(\"cuda:0\")\n",
    "e_vectors = E(x.float(), y.float()).reshape(dims[0], dims[1], -1)  # B, K, len(e)\n",
    "e_hat = e_vectors.mean(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 512])\n"
     ]
    }
   ],
   "source": [
    "print(e_hat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "relu(): argument 'input' (position 1) must be Tensor, not ZeroPad2d",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-93baa4b32f9e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mG\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda:0\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mx_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mx_hat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mG\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me_hat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/PyTorch/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-e0a256ce98b5>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, y, e)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m         \u001b[0;31m# Encode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min11_e\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv11\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min12_e\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv12\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min1_e\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# [B, 64, 128, 128]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PyTorch/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-f74608748aa5>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0;31m# Right Side\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_r1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PyTorch/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mrelu\u001b[0;34m(input, inplace)\u001b[0m\n\u001b[1;32m    912\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    913\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 914\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    915\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: relu(): argument 'input' (position 1) must be Tensor, not ZeroPad2d"
     ]
    }
   ],
   "source": [
    "G = Generator(\"cuda:0\")\n",
    "x_t, y_t = data[:, 0, ...], data[:, 1, ...]\n",
    "x_hat = G(y_t, e_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
